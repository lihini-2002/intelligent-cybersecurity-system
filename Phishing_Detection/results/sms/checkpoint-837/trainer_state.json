{
  "best_global_step": 837,
  "best_metric": 0.9627118644067797,
  "best_model_checkpoint": "../results/sms/checkpoint-837",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 837,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.035842293906810034,
      "grad_norm": 10.862772941589355,
      "learning_rate": 9e-07,
      "loss": 0.6783,
      "step": 10
    },
    {
      "epoch": 0.07168458781362007,
      "grad_norm": 8.120943069458008,
      "learning_rate": 1.9e-06,
      "loss": 0.6303,
      "step": 20
    },
    {
      "epoch": 0.10752688172043011,
      "grad_norm": 8.84901237487793,
      "learning_rate": 2.9e-06,
      "loss": 0.5618,
      "step": 30
    },
    {
      "epoch": 0.14336917562724014,
      "grad_norm": 2.476869821548462,
      "learning_rate": 3.9e-06,
      "loss": 0.4945,
      "step": 40
    },
    {
      "epoch": 0.17921146953405018,
      "grad_norm": 3.6787428855895996,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 0.4835,
      "step": 50
    },
    {
      "epoch": 0.21505376344086022,
      "grad_norm": 3.099090337753296,
      "learning_rate": 5.9e-06,
      "loss": 0.359,
      "step": 60
    },
    {
      "epoch": 0.25089605734767023,
      "grad_norm": 3.0679962635040283,
      "learning_rate": 6.900000000000001e-06,
      "loss": 0.2466,
      "step": 70
    },
    {
      "epoch": 0.2867383512544803,
      "grad_norm": 2.114955186843872,
      "learning_rate": 7.9e-06,
      "loss": 0.1639,
      "step": 80
    },
    {
      "epoch": 0.3225806451612903,
      "grad_norm": 3.612274408340454,
      "learning_rate": 8.9e-06,
      "loss": 0.133,
      "step": 90
    },
    {
      "epoch": 0.35842293906810035,
      "grad_norm": 2.0559542179107666,
      "learning_rate": 9.900000000000002e-06,
      "loss": 0.0761,
      "step": 100
    },
    {
      "epoch": 0.3942652329749104,
      "grad_norm": 1.0483269691467285,
      "learning_rate": 1.09e-05,
      "loss": 0.0854,
      "step": 110
    },
    {
      "epoch": 0.43010752688172044,
      "grad_norm": 2.499213218688965,
      "learning_rate": 1.19e-05,
      "loss": 0.0672,
      "step": 120
    },
    {
      "epoch": 0.4659498207885305,
      "grad_norm": 1.7923564910888672,
      "learning_rate": 1.29e-05,
      "loss": 0.0241,
      "step": 130
    },
    {
      "epoch": 0.5017921146953405,
      "grad_norm": 3.787414073944092,
      "learning_rate": 1.3900000000000002e-05,
      "loss": 0.0625,
      "step": 140
    },
    {
      "epoch": 0.5376344086021505,
      "grad_norm": 0.11799486726522446,
      "learning_rate": 1.49e-05,
      "loss": 0.0711,
      "step": 150
    },
    {
      "epoch": 0.5734767025089605,
      "grad_norm": 0.24368862807750702,
      "learning_rate": 1.59e-05,
      "loss": 0.0318,
      "step": 160
    },
    {
      "epoch": 0.6093189964157706,
      "grad_norm": 0.17801693081855774,
      "learning_rate": 1.69e-05,
      "loss": 0.0309,
      "step": 170
    },
    {
      "epoch": 0.6451612903225806,
      "grad_norm": 0.08736734837293625,
      "learning_rate": 1.79e-05,
      "loss": 0.1006,
      "step": 180
    },
    {
      "epoch": 0.6810035842293907,
      "grad_norm": 0.19409367442131042,
      "learning_rate": 1.8900000000000002e-05,
      "loss": 0.0572,
      "step": 190
    },
    {
      "epoch": 0.7168458781362007,
      "grad_norm": 15.727377891540527,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 0.0135,
      "step": 200
    },
    {
      "epoch": 0.7526881720430108,
      "grad_norm": 0.05152052268385887,
      "learning_rate": 2.09e-05,
      "loss": 0.0037,
      "step": 210
    },
    {
      "epoch": 0.7885304659498208,
      "grad_norm": 0.05634378641843796,
      "learning_rate": 2.19e-05,
      "loss": 0.0711,
      "step": 220
    },
    {
      "epoch": 0.8243727598566308,
      "grad_norm": 0.03329550102353096,
      "learning_rate": 2.29e-05,
      "loss": 0.0332,
      "step": 230
    },
    {
      "epoch": 0.8602150537634409,
      "grad_norm": 19.931018829345703,
      "learning_rate": 2.39e-05,
      "loss": 0.075,
      "step": 240
    },
    {
      "epoch": 0.8960573476702509,
      "grad_norm": 8.73525333404541,
      "learning_rate": 2.4900000000000002e-05,
      "loss": 0.0088,
      "step": 250
    },
    {
      "epoch": 0.931899641577061,
      "grad_norm": 2.1928815841674805,
      "learning_rate": 2.5900000000000003e-05,
      "loss": 0.0448,
      "step": 260
    },
    {
      "epoch": 0.967741935483871,
      "grad_norm": 0.051904238760471344,
      "learning_rate": 2.6900000000000003e-05,
      "loss": 0.0381,
      "step": 270
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.989237668161435,
      "eval_f1": 0.959731543624161,
      "eval_loss": 0.04874810203909874,
      "eval_precision": 0.959731543624161,
      "eval_recall": 0.959731543624161,
      "eval_runtime": 12.9222,
      "eval_samples_per_second": 86.286,
      "eval_steps_per_second": 5.417,
      "step": 279
    },
    {
      "epoch": 1.003584229390681,
      "grad_norm": 0.16537123918533325,
      "learning_rate": 2.7900000000000004e-05,
      "loss": 0.0753,
      "step": 280
    },
    {
      "epoch": 1.039426523297491,
      "grad_norm": 0.049613725394010544,
      "learning_rate": 2.8899999999999998e-05,
      "loss": 0.0043,
      "step": 290
    },
    {
      "epoch": 1.075268817204301,
      "grad_norm": 0.2715500295162201,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 0.0367,
      "step": 300
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 1.7874410152435303,
      "learning_rate": 3.09e-05,
      "loss": 0.0154,
      "step": 310
    },
    {
      "epoch": 1.146953405017921,
      "grad_norm": 0.05383094772696495,
      "learning_rate": 3.19e-05,
      "loss": 0.1096,
      "step": 320
    },
    {
      "epoch": 1.1827956989247312,
      "grad_norm": 0.06954482197761536,
      "learning_rate": 3.29e-05,
      "loss": 0.0339,
      "step": 330
    },
    {
      "epoch": 1.2186379928315412,
      "grad_norm": 0.05668804049491882,
      "learning_rate": 3.3900000000000004e-05,
      "loss": 0.0086,
      "step": 340
    },
    {
      "epoch": 1.2544802867383513,
      "grad_norm": 0.03174814581871033,
      "learning_rate": 3.49e-05,
      "loss": 0.0017,
      "step": 350
    },
    {
      "epoch": 1.2903225806451613,
      "grad_norm": 0.021223539486527443,
      "learning_rate": 3.59e-05,
      "loss": 0.0019,
      "step": 360
    },
    {
      "epoch": 1.3261648745519714,
      "grad_norm": 26.392200469970703,
      "learning_rate": 3.69e-05,
      "loss": 0.0881,
      "step": 370
    },
    {
      "epoch": 1.3620071684587813,
      "grad_norm": 0.02846340462565422,
      "learning_rate": 3.79e-05,
      "loss": 0.001,
      "step": 380
    },
    {
      "epoch": 1.3978494623655915,
      "grad_norm": 0.0430276058614254,
      "learning_rate": 3.8900000000000004e-05,
      "loss": 0.0278,
      "step": 390
    },
    {
      "epoch": 1.4336917562724014,
      "grad_norm": 0.06573207676410675,
      "learning_rate": 3.99e-05,
      "loss": 0.0519,
      "step": 400
    },
    {
      "epoch": 1.4695340501792113,
      "grad_norm": 0.03199515864253044,
      "learning_rate": 4.09e-05,
      "loss": 0.0091,
      "step": 410
    },
    {
      "epoch": 1.5053763440860215,
      "grad_norm": 0.12145029753446579,
      "learning_rate": 4.19e-05,
      "loss": 0.0013,
      "step": 420
    },
    {
      "epoch": 1.5412186379928317,
      "grad_norm": 0.015224315226078033,
      "learning_rate": 4.29e-05,
      "loss": 0.001,
      "step": 430
    },
    {
      "epoch": 1.5770609318996416,
      "grad_norm": 0.08854782581329346,
      "learning_rate": 4.39e-05,
      "loss": 0.0822,
      "step": 440
    },
    {
      "epoch": 1.6129032258064515,
      "grad_norm": 0.09109179675579071,
      "learning_rate": 4.49e-05,
      "loss": 0.0531,
      "step": 450
    },
    {
      "epoch": 1.6487455197132617,
      "grad_norm": 6.636611461639404,
      "learning_rate": 4.5900000000000004e-05,
      "loss": 0.0439,
      "step": 460
    },
    {
      "epoch": 1.6845878136200718,
      "grad_norm": 5.845256328582764,
      "learning_rate": 4.69e-05,
      "loss": 0.0588,
      "step": 470
    },
    {
      "epoch": 1.7204301075268817,
      "grad_norm": 0.04871181771159172,
      "learning_rate": 4.79e-05,
      "loss": 0.0759,
      "step": 480
    },
    {
      "epoch": 1.7562724014336917,
      "grad_norm": 0.029241004958748817,
      "learning_rate": 4.89e-05,
      "loss": 0.0019,
      "step": 490
    },
    {
      "epoch": 1.7921146953405018,
      "grad_norm": 0.0572495199739933,
      "learning_rate": 4.99e-05,
      "loss": 0.0982,
      "step": 500
    },
    {
      "epoch": 1.827956989247312,
      "grad_norm": 0.02843562886118889,
      "learning_rate": 4.8664688427299705e-05,
      "loss": 0.0324,
      "step": 510
    },
    {
      "epoch": 1.863799283154122,
      "grad_norm": 0.06992891430854797,
      "learning_rate": 4.7181008902077156e-05,
      "loss": 0.031,
      "step": 520
    },
    {
      "epoch": 1.8996415770609318,
      "grad_norm": 0.013849172741174698,
      "learning_rate": 4.56973293768546e-05,
      "loss": 0.0142,
      "step": 530
    },
    {
      "epoch": 1.935483870967742,
      "grad_norm": 0.025680216029286385,
      "learning_rate": 4.421364985163205e-05,
      "loss": 0.0007,
      "step": 540
    },
    {
      "epoch": 1.971326164874552,
      "grad_norm": 0.007207361049950123,
      "learning_rate": 4.2729970326409497e-05,
      "loss": 0.0007,
      "step": 550
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9829596412556054,
      "eval_f1": 0.9385113268608414,
      "eval_loss": 0.08382613211870193,
      "eval_precision": 0.90625,
      "eval_recall": 0.9731543624161074,
      "eval_runtime": 18.8065,
      "eval_samples_per_second": 59.288,
      "eval_steps_per_second": 3.722,
      "step": 558
    },
    {
      "epoch": 2.007168458781362,
      "grad_norm": 0.010327646508812904,
      "learning_rate": 4.124629080118694e-05,
      "loss": 0.0007,
      "step": 560
    },
    {
      "epoch": 2.043010752688172,
      "grad_norm": 63.598670959472656,
      "learning_rate": 3.976261127596439e-05,
      "loss": 0.0149,
      "step": 570
    },
    {
      "epoch": 2.078853046594982,
      "grad_norm": 0.004649962764233351,
      "learning_rate": 3.8278931750741844e-05,
      "loss": 0.0419,
      "step": 580
    },
    {
      "epoch": 2.1146953405017923,
      "grad_norm": 0.004549236502498388,
      "learning_rate": 3.679525222551929e-05,
      "loss": 0.0002,
      "step": 590
    },
    {
      "epoch": 2.150537634408602,
      "grad_norm": 0.004576114472001791,
      "learning_rate": 3.531157270029673e-05,
      "loss": 0.0003,
      "step": 600
    },
    {
      "epoch": 2.186379928315412,
      "grad_norm": 0.01954886130988598,
      "learning_rate": 3.382789317507419e-05,
      "loss": 0.0541,
      "step": 610
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 8.407108306884766,
      "learning_rate": 3.2344213649851636e-05,
      "loss": 0.0721,
      "step": 620
    },
    {
      "epoch": 2.258064516129032,
      "grad_norm": 0.06625030189752579,
      "learning_rate": 3.086053412462908e-05,
      "loss": 0.0021,
      "step": 630
    },
    {
      "epoch": 2.293906810035842,
      "grad_norm": 7.228280544281006,
      "learning_rate": 2.937685459940653e-05,
      "loss": 0.0417,
      "step": 640
    },
    {
      "epoch": 2.3297491039426523,
      "grad_norm": 0.014512949623167515,
      "learning_rate": 2.789317507418398e-05,
      "loss": 0.0006,
      "step": 650
    },
    {
      "epoch": 2.3655913978494625,
      "grad_norm": 0.008450095541775227,
      "learning_rate": 2.6409495548961428e-05,
      "loss": 0.0005,
      "step": 660
    },
    {
      "epoch": 2.4014336917562726,
      "grad_norm": 0.008097654208540916,
      "learning_rate": 2.4925816023738872e-05,
      "loss": 0.0003,
      "step": 670
    },
    {
      "epoch": 2.4372759856630823,
      "grad_norm": 0.00834015104919672,
      "learning_rate": 2.344213649851632e-05,
      "loss": 0.0416,
      "step": 680
    },
    {
      "epoch": 2.4731182795698925,
      "grad_norm": 0.007024287711828947,
      "learning_rate": 2.195845697329377e-05,
      "loss": 0.0485,
      "step": 690
    },
    {
      "epoch": 2.5089605734767026,
      "grad_norm": 0.007407828234136105,
      "learning_rate": 2.0474777448071216e-05,
      "loss": 0.0004,
      "step": 700
    },
    {
      "epoch": 2.5448028673835124,
      "grad_norm": 0.005073866341263056,
      "learning_rate": 1.8991097922848668e-05,
      "loss": 0.0004,
      "step": 710
    },
    {
      "epoch": 2.5806451612903225,
      "grad_norm": 0.0070787593722343445,
      "learning_rate": 1.7507418397626112e-05,
      "loss": 0.0003,
      "step": 720
    },
    {
      "epoch": 2.6164874551971327,
      "grad_norm": 0.006070333998650312,
      "learning_rate": 1.6023738872403564e-05,
      "loss": 0.0004,
      "step": 730
    },
    {
      "epoch": 2.652329749103943,
      "grad_norm": 0.004844226408749819,
      "learning_rate": 1.454005934718101e-05,
      "loss": 0.0003,
      "step": 740
    },
    {
      "epoch": 2.688172043010753,
      "grad_norm": 0.015254455618560314,
      "learning_rate": 1.3056379821958458e-05,
      "loss": 0.0145,
      "step": 750
    },
    {
      "epoch": 2.7240143369175627,
      "grad_norm": 0.027593666687607765,
      "learning_rate": 1.1572700296735906e-05,
      "loss": 0.0004,
      "step": 760
    },
    {
      "epoch": 2.759856630824373,
      "grad_norm": 0.0052034733816981316,
      "learning_rate": 1.0089020771513354e-05,
      "loss": 0.0003,
      "step": 770
    },
    {
      "epoch": 2.795698924731183,
      "grad_norm": 0.059130724519491196,
      "learning_rate": 8.605341246290802e-06,
      "loss": 0.0164,
      "step": 780
    },
    {
      "epoch": 2.8315412186379927,
      "grad_norm": 0.007058572955429554,
      "learning_rate": 7.12166172106825e-06,
      "loss": 0.0003,
      "step": 790
    },
    {
      "epoch": 2.867383512544803,
      "grad_norm": 0.004829990677535534,
      "learning_rate": 5.637982195845697e-06,
      "loss": 0.0003,
      "step": 800
    },
    {
      "epoch": 2.903225806451613,
      "grad_norm": 0.00787329114973545,
      "learning_rate": 4.154302670623145e-06,
      "loss": 0.0002,
      "step": 810
    },
    {
      "epoch": 2.9390681003584227,
      "grad_norm": 0.004782005678862333,
      "learning_rate": 2.6706231454005935e-06,
      "loss": 0.0005,
      "step": 820
    },
    {
      "epoch": 2.974910394265233,
      "grad_norm": 0.004616441670805216,
      "learning_rate": 1.1869436201780417e-06,
      "loss": 0.0239,
      "step": 830
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9901345291479821,
      "eval_f1": 0.9627118644067797,
      "eval_loss": 0.0487360805273056,
      "eval_precision": 0.9726027397260274,
      "eval_recall": 0.9530201342281879,
      "eval_runtime": 13.0283,
      "eval_samples_per_second": 85.583,
      "eval_steps_per_second": 5.373,
      "step": 837
    }
  ],
  "logging_steps": 10,
  "max_steps": 837,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 879514480304640.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}

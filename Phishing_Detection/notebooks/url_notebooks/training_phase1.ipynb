{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XgFefVDvjx_",
        "outputId": "12be381d-cb38-4367-bfe0-5fe0dbdc390b"
      },
      "outputs": [],
      "source": [
        "!pip install transformers pandas scikit-learn torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wqEhJwGWwt08"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FygfQXRsxbWf",
        "outputId": "c2e7a850-c39b-4b06-c36e-ca5e2840bcc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tjy6TC3RxmwM"
      },
      "outputs": [],
      "source": [
        "def batch_tokenize(texts, labels, tokenizer, batch_size=10000):\n",
        "    all_encodings = {\"input_ids\": [], \"attention_mask\": []}\n",
        "    all_labels = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i+batch_size]\n",
        "        batch_labels = labels[i:i+batch_size]\n",
        "        batch_enc = tokenizer(batch_texts, truncation=True, padding=True, return_tensors=\"pt\")\n",
        "        all_encodings[\"input_ids\"].extend(batch_enc[\"input_ids\"])\n",
        "        all_encodings[\"attention_mask\"].extend(batch_enc[\"attention_mask\"])\n",
        "        all_labels.extend(batch_labels)\n",
        "    return all_encodings, all_labels\n",
        "\n",
        "class PhishingDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            key: self.encodings[key][idx] for key in self.encodings\n",
        "        } | {\"labels\": torch.tensor(self.labels[idx])}\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = logits.argmax(axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMS9k_oTxsJp"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"/content/drive/MyDrive/phishing_chunks/phishing_urls_part1.csv\"\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    df[\"url\"].tolist(), df[\"label\"].tolist(),\n",
        "    test_size=0.2, stratify=df[\"label\"], random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XG0qvsmQrvHH"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "train_encodings, train_labels_final = batch_tokenize(train_texts, train_labels, tokenizer)\n",
        "test_encodings, test_labels_final = batch_tokenize(test_texts, test_labels, tokenizer)\n",
        "train_dataset = PhishingDataset(train_encodings, train_labels_final)\n",
        "test_dataset = PhishingDataset(test_encodings, test_labels_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0K8upCEsGIo",
        "outputId": "7d69b95e-e162-4b76-8af9-df962856a620"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model_path = \"/content/drive/MyDrive/phishing_model_checkpoint\"\n",
        "try:\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
        "except:\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "trIZ5TADsJ2T"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=model_path,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"/content/drive/MyDrive/phishing_logs\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    save_total_limit=2,\n",
        "    logging_steps=50,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=data_collator\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "XTo-MBMJsTkM",
        "outputId": "13e705fb-a41c-4652-c959-b870951109fe"
      },
      "outputs": [],
      "source": [
        "trainer.train()\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "p2ltai5CXw-B"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"/content/drive/MyDrive/phishing_model_v1_after_phase1\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
